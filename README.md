# teamfloripa-hackathon-darwin
Projeto da equipe Floripa para o Hackathon da Darwin AI

# Desempenho IA

Trata-se de uma feature integrada Ã  plataforma Darwin AI que mede a qualidade e consistÃªncia dos assistentes de IA criados para empresas.  
Ele permite acompanhar mÃ©tricas de performance, evoluÃ§Ã£o e aderÃªncia ao prompt configurado, tanto durante o onboarding quanto apÃ³s o lanÃ§amento do assistente.

---

## ğŸ¯ Objetivo

O objetivo do projeto Ã© oferecer uma camada de **monitoramento e diagnÃ³stico de qualidade** para cada assistente, de modo que as empresas e o time Darwin possam:

- Entender se o assistente estÃ¡ seguindo o prompt corretamente;  
- Detectar respostas incoerentes ou inconsistentes com a base de conhecimento;  

ğŸ’¡ **Por que isso importa:**  
Hoje, os times da Darwin e os clientes precisam avaliar manualmente se um assistente â€œestÃ¡ bomâ€.  
Essa ferramenta automatiza esse processo, gerando confianÃ§a, agilidade e transparÃªncia no produto.

## ğŸ§© Contexto de desenvolvimento

**Inicialmente usamos o Vercel v0 para acelerar a construÃ§Ã£o da interface**, e a partir daÃ­ estamos implementando **ajustes e camadas complementares** que adicionam lÃ³gica de avaliaÃ§Ã£o, cÃ¡lculo de mÃ©tricas e integraÃ§Ã£o com a plataforma Darwin AI.  
Este repositÃ³rio concentra **o backend, documentaÃ§Ã£o tÃ©cnica e explicaÃ§Ã£o** que somam ao cÃ³digo gerado no Vercel.
---
## ConfiguraÃ§Ã£o

### 1. Adicionar API Key do OpenAI

Para usar a anÃ¡lise de conversas, vocÃª precisa adicionar sua API key do OpenAI:

1. Acesse [platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. Crie uma nova API key
3. No v0, clique no Ã­cone de **Vars** (variÃ¡veis) na barra lateral esquerda
4. Adicione uma nova variÃ¡vel:
   - **Nome**: `OPENAI_API_KEY`
   - **Valor**: Sua API key do OpenAI (comeÃ§a com `sk-...`)

### 2. Como Usar

1. A plataforma carrega automaticamente as conversas do CSV
2. Clique no botÃ£o **"Analisar Conversas"** para iniciar a anÃ¡lise
3. O sistema processa as conversas em lotes de 3 simultaneamente
4. Cada conversa recebe:
   - PontuaÃ§Ã£o geral (0-100)
   - MÃ©tricas detalhadas (aderÃªncia Ã  missÃ£o, coerÃªncia, diretrizes, qualidade)
   - AnÃ¡lise linha por linha
   - IdentificaÃ§Ã£o de desvios
   - SugestÃµes de melhoria

### 3. Recursos

- **Processamento Paralelo**: Analisa mÃºltiplas conversas simultaneamente
- **AnÃ¡lise Detalhada**: Cada linha da conversa Ã© avaliada individualmente
- **MÃ©tricas EspecÃ­ficas**: AderÃªncia Ã  missÃ£o, coerÃªncia contextual, seguimento de diretrizes e qualidade
- **Feedback AcionÃ¡vel**: SugestÃµes especÃ­ficas de melhoria
- **Interface Visual**: Cores indicativas (verde=bom, amarelo=atenÃ§Ã£o, vermelho=problema)

### 4. Custos

A anÃ¡lise usa a API do OpenAI (GPT-4), que tem custos associados. Cada anÃ¡lise consome tokens baseado no tamanho da conversa. Monitore seu uso em [platform.openai.com/usage](https://platform.openai.com/usage).

---

## ğŸ“Š MÃ©tricas Avaliadas

| MÃ©trica | O que mede | InterpretaÃ§Ã£o |
|----------|-------------|----------------|
| **Adherence to Mission** | AderÃªncia Ã  missÃ£o do assistente | Se o assistente cumpre o objetivo principal configurado no prompt |
| **Context Coherence** | CoerÃªncia de contexto | Se mantÃ©m o raciocÃ­nio e evita contradiÃ§Ãµes |
| **Guideline Compliance** | Conformidade com regras | Se usa os *Prompt Templates* e *Transition Tools* corretamente |
| **Response Quality** | Clareza e utilidade das respostas | Se responde de forma clara, Ãºtil e completa |
| **Overall Score** | Nota geral (0â€“100) | MÃ©dia ponderada das mÃ©tricas acima |

As mÃ©tricas variam de **0 a 100**, sendo:
- **80â€“100:** excelente  
- **60â€“79:** precisa de ajustes  
- **0â€“59:** desempenho crÃ­tico  

---

## ğŸ’¸ Impacto no NegÃ³cio

- **Acelera o lanÃ§amento** de novos assistentes (contas prontas mais rÃ¡pido).  
- **Reduz churn** com assistentes mais consistentes e confiÃ¡veis.  
- **Diminui custo operacional**, eliminando revisÃµes manuais.  
- **DÃ¡ visibilidade** ao desempenho do assistente e como tem se saÃ­do

---

## ğŸ“š DocumentaÃ§Ã£o

- [MÃ©tricas](docs/metrics.md)  
- [Roadmap](docs/roadmap.md)

---

## ğŸ§  VisÃ£o de Produto

O **Desempenho IA** transforma a avaliaÃ§Ã£o de qualidade dos assistentes â€”  
de um processo manual e subjetivo para uma camada automÃ¡tica, objetiva e mensurÃ¡vel.  
Isso gera confianÃ§a, melhora a experiÃªncia do cliente e fortalece o produto Darwin AI.

---

## ğŸ“„ LicenÃ§a

MIT Â© 2025 Team Floripa
